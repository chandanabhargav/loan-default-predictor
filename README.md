
# ğŸš€ Loan Default Prediction API

A FastAPI-powered machine learning service for predicting loan default risk, trained on Lending Club data.  
Supports real-time predictions, monitoring, and integration with MLflow for model versioning.

---

## ğŸ“¦ Features

| Feature                        | Description                                      |
|-------------------------------|--------------------------------------------------|
| ğŸ§  Model                      | XGBoost, trained on Lending Club loan data       |
| âš™ï¸ API                        | Built with FastAPI for real-time scoring         |
| ğŸ” Monitoring                 | Logs prediction, confidence score, model version |
| ğŸ“¦ Model Versioning           | Uses MLflow Registry to load production models   |
| ğŸ§ª Sample Payload             | Included in `/docs` for easy testing             |
| ğŸ› ï¸ Docker Support             | Lightweight containerized deployment             |
| ğŸ—ï¸ Airflow                    | Scheduled batch inference                        |
                                 
---

## ğŸš€ Quick Start (Local)

### 1. Clone the Repo

```bash
git clone https://github.com/your-org/loan-default-api.git
cd loan-default-api
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Start the API

```bash
uvicorn app:app --reload
```

### 4. Open Swagger UI

Go to [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ§ª Sample Request

```json
{
  "loan_amnt": 12000,
  "funded_amnt": 12000,
  "term": " 36 months",
  "int_rate": 14.32,
  "emp_length": "10+ years",
  "home_ownership": "RENT",
  "annual_inc": 60000,
  "verification_status": "Verified",
  "purpose": "credit_card",
  "dti": 15.7,
  "delinq_2yrs": 0
}
```

---

## ğŸ“¤ Sample Response

```json
{
  "default_probability": 0.71,
  "prediction": 1,
  "confidence_label": "High Risk",
  "model_version": "1.0.0"
}
```

---

## ğŸ§  Monitoring

| Field              | Logged           |
|-------------------|------------------|
| Timestamp          | âœ…               |
| Input features     | âœ…               |
| Prediction         | âœ…               |
| Probability score  | âœ…               |
| Risk label         | âœ…               |
| Model version      | âœ…               |

All logs are stored in `inference.log`.

---

## ğŸ³ Docker Deployment

### Build the Image

```bash
docker build -t loan-default-api .
```

### Run the Container

```bash
docker run -d -p 8000:8000 loan-default-api
```

Then visit [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“¦ MLflow Integration

This project uses MLflow for **experiment tracking** and **model logging** during training.

- Metrics (e.g. AUC, F1)
- Parameters (e.g. model type, learning rate)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                    # FastAPI app
â”œâ”€â”€ inference.log             # Logs predictions
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ xgboost_random_search.pkl # (or use MLflow registry)
```

---

## ğŸ›¡ï¸ Health Check

```bash
GET /health
Response: {"status": "ok"}
```

---

## âœ¨ License

MIT â€” free to use, modify, and distribute.

---

## ğŸ‘¨â€ğŸ’» Author

**Chandana**  
[https://github.com/chandanabhargav](https://github.com/chandanabhargav)

---

## ğŸ—ï¸ Batch Scoring with Airflow

This project supports scheduled batch inference using Apache Airflow.  

### ğŸ“‚ Structure

```
airflow_dags/
â””â”€â”€ loan_default_dag.py    # DAG to run batch_predict.py
batch/
â”œâ”€â”€ batch_predict.py       # Reads input CSV, scores, saves output
â””â”€â”€ input/
    â””â”€â”€ new_loans.csv      # Sample input data
```

### ğŸ› ï¸ How It Works

1. Pulls daily loan applications (e.g., from `new_loans.csv` or S3)
2. Runs batch scoring using your trained model
3. Writes predictions to a CSV or target system
4. Scheduled via Airflow DAG

### ğŸ§ª Run DAG Locally

1. Install Airflow (suggested in a virtualenv):
    ```bash
    pip install apache-airflow
    ```

2. Set up airflow directories:
    ```bash
    export AIRFLOW_HOME=~/airflow
    airflow db init
    ```

3. Copy `loan_default_dag.py` into `~/airflow/dags/`

4. Start the Airflow scheduler and web UI:
    ```bash
    airflow scheduler
    airflow webserver --port 8080
    ```

5. Visit the UI: [http://localhost:8080](http://localhost:8080)

6. Enable and trigger the DAG: `loan_default_batch_prediction`

---

## ğŸ“Œ Example Batch Command

```bash
python batch/batch_predict.py
```

Outputs predictions to: `predictions.csv`

---

## ğŸ“… Schedule

The DAG is configured to run **nightly**:
```python
schedule_interval="@daily"
start_date=datetime(2025, 1, 1)
```

Update to your desired schedule in `loan_default_dag.py`.